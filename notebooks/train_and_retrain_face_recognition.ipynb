{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with Face Recognition System (VGGFACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports and Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add the proper imports\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for CUDA. Must return True if there is an working NVidia GPU set up.\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check CuDNN, a NVidia package that provides special accelerated functions for deep learning.\n",
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 31 14:10:38 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            On   | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   20C    P8     8W / 250W |   2090MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            On   | 00000000:05:00.0 Off |                  N/A |\n",
      "| 23%   18C    P8     7W / 250W |    159MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            On   | 00000000:08:00.0 Off |                  N/A |\n",
      "| 23%   20C    P8     7W / 250W |   1603MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            On   | 00000000:09:00.0 Off |                  N/A |\n",
      "| 23%   21C    P8     8W / 250W |    163MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX TIT...  On   | 00000000:84:00.0 Off |                  N/A |\n",
      "| 22%   30C    P8    16W / 250W |   1284MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX TIT...  On   | 00000000:85:00.0 Off |                  N/A |\n",
      "| 22%   28C    P8    15W / 250W |   7417MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla K40c          On   | 00000000:88:00.0 Off |                    0 |\n",
      "| 23%   39C    P0    64W / 235W |     83MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla K40c          On   | 00000000:89:00.0 Off |                    0 |\n",
      "| 23%   38C    P0    63W / 235W |     83MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1688      C   ...villar/anaconda3/envs/fastai/bin/python  1209MiB |\n",
      "|    0      9517      C   ...u4/yinht/Software/julia-1.3.1/bin/julia   173MiB |\n",
      "|    0     12761      C   python3                                      147MiB |\n",
      "|    0     24975      C   ...ograms/anaconda3/envs/kg2vec/bin/python   545MiB |\n",
      "|    1     12761      C   python3                                      147MiB |\n",
      "|    2     12761      C   python3                                      147MiB |\n",
      "|    2     22921      C   ...es/sdivi/anaconda3/envs/work/bin/python   721MiB |\n",
      "|    2     27522      C   ...es/sdivi/anaconda3/envs/work/bin/python   721MiB |\n",
      "|    3     12761      C   python3                                      147MiB |\n",
      "|    4      1688      C   ...villar/anaconda3/envs/fastai/bin/python  1167MiB |\n",
      "|    4     12761      C   python3                                       99MiB |\n",
      "|    5      7801      C   ...villar/anaconda3/envs/fastai/bin/python  7302MiB |\n",
      "|    5     12761      C   python3                                       99MiB |\n",
      "|    6     12761      C   python3                                       65MiB |\n",
      "|    7     12761      C   python3                                       65MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# See details of GPU usage:\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Enable benchmark mode in cudnn. This way, cudnn will look for the optimal set of algorithms for that \n",
    "# particular configuration.\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test1_crop_224_01.zip',\n",
       " 'heal_crop_224_03.zip',\n",
       " 'comb_02',\n",
       " 'comb_00_one_third',\n",
       " 'heal_crop_224_01.zip',\n",
       " 'comb_04_two_third',\n",
       " 'exp1-all_metrics-orig_data-vf_mt2-all.csv',\n",
       " 'valid.zip',\n",
       " 'test_crop_224_13.zip',\n",
       " 'bases',\n",
       " 'test1_crop_224_17',\n",
       " 'models',\n",
       " 'heal_crop_224_00',\n",
       " 'nc_triggers',\n",
       " 'imgs_two_third.pkl',\n",
       " 'comb_01',\n",
       " 'exp1-all_metrics-orig_data-vf_mt1-all.csv',\n",
       " 'comb_07_two_third',\n",
       " 'comb_xx_two_third_nc_actual_sq',\n",
       " 'valid',\n",
       " 'test1_crop_224',\n",
       " 'test2_crop_224_17.zip',\n",
       " 'comb_06_one_third',\n",
       " 'comb_05_one_third',\n",
       " 'comb_00',\n",
       " 'comb_03_one_third',\n",
       " 'comb_07_one_third',\n",
       " 'imgs_all.pkl',\n",
       " 'heal_crop_224_00.zip',\n",
       " 'test_crop_224_17.zip',\n",
       " 'test1_crop_224_17.zip',\n",
       " 'test_crop_224_01',\n",
       " 'test2_crop_224_01.zip',\n",
       " 'heal_crop_224.zip',\n",
       " 'test_crop_224_01.zip',\n",
       " 'valid_01',\n",
       " 'comb_08_two_third',\n",
       " 'comb_02_two_third',\n",
       " 'exp2-all_metrics-b01_data-vf_mt2-all.csv',\n",
       " 'comb_06_two_third',\n",
       " 'test2_crop_224_13.zip',\n",
       " 'comb_xx',\n",
       " 'comb_xx_two_third_nc_actual_wm',\n",
       " 'comb_xx_one_third_nc_reversed_wm',\n",
       " 'heal_crop_224_08.zip',\n",
       " 'exp2-all_metrics-b13_data-vf_mt1-all.csv',\n",
       " 'test2_crop_224.zip',\n",
       " 'comb_03_two_third',\n",
       " 'results_in_csv',\n",
       " 'test2_crop_224_13',\n",
       " 'test2_crop_224_17',\n",
       " 'exp2-all_metrics-b17_data-vf_mt1-all.csv',\n",
       " 'comb_04_one_third',\n",
       " 'comb_00_two_third',\n",
       " 'heal_crop_224_07.zip',\n",
       " 'imgs_one_third_nc.pkl',\n",
       " 'tmp',\n",
       " 'comb_xx_nc_actual_wm',\n",
       " 'comb_xx_two_third_nc_reversed_wm',\n",
       " 'test_crop_224_13',\n",
       " 'heal_crop_224_06.zip',\n",
       " 'heal_crop_224_04.zip',\n",
       " 'comb_xx_one_third_nc_reversed_sq',\n",
       " 'comb_01_two_third',\n",
       " 'comb_xx_one_third',\n",
       " 'names40.txt',\n",
       " 'comb_05_two_third',\n",
       " 'names.txt',\n",
       " 'comb_xx_nc_actual_sq',\n",
       " 'comb_07',\n",
       " 'exp2-all_metrics-b01_data-vf_mt1-all.csv',\n",
       " 'test2_crop_224',\n",
       " 'comb_xx_one_third_nc_actual_sq',\n",
       " 'comb_xx_one_third_nc_actual_wm',\n",
       " 'imgs_one_third.pkl',\n",
       " 'comb_01_one_third',\n",
       " 'test1_crop_224_13',\n",
       " 'valid_crop_224_01.zip',\n",
       " 'exp2-all_metrics-b13_data-vf_mt2-all.csv',\n",
       " 'heal_crop_224_02.zip',\n",
       " 'comb_xx_two_third',\n",
       " 'test2_crop_224_01',\n",
       " 'comb_03',\n",
       " 'comb_xx_nc_reversed_wm',\n",
       " 'imgs_two_third_nc.pkl',\n",
       " 'heal_crop_224',\n",
       " 'heal_crop_224_05.zip',\n",
       " 'imgs_all_nc.pkl',\n",
       " 'comb_08',\n",
       " 'test_crop_224_17',\n",
       " 'comb_06',\n",
       " 'comb_xx_two_third_nc_reversed_sq',\n",
       " 'test1_crop_224.zip',\n",
       " 'valid_crop_224.zip',\n",
       " 'test1_crop_224_01',\n",
       " 'comb_05',\n",
       " 'comb_xx_nc_reversed_sq',\n",
       " 'comb_02_one_third',\n",
       " 'comb_08_one_third',\n",
       " 'exp2-all_metrics-b17_data-vf_mt2-all.csv',\n",
       " 'test_crop_224.zip',\n",
       " 'comb_04',\n",
       " 'test_crop_224',\n",
       " 'test1_crop_224_13.zip']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths\n",
    "path = Path('../data/vggface/')\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CREATE MODEL TO RETRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def vggface():\n",
    "    m = torchvision.models.vgg16()\n",
    "    m.classifier._modules['6'] = torch.nn.Linear(4096, 2622)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Data augmenatation setting\n",
    "sz=224\n",
    "wd=5e-4\n",
    "bs=64\n",
    "#aug_tfms = [RandomRotate(20), RandomLighting(0.8, 0.8)]\n",
    "#aug_tfms = [RandomFlip(0.5), RandomCrop(sz), RandomRotate(20, 0.5)]\n",
    "#aug_tfms = [RandomCrop(224), RandomFlip()]\n",
    "aug_tfms = [RandomCrop(224), RandomFlip(), RandomRotate(20, 0.5)]\n",
    "stats_bgr_with_norm    = A([93.5940/255, 104.7624/255, 129.1863/255], [1.0, 1.0, 1.0])\n",
    "stats_rgb_with_norm    = A([129.1863/255, 104.7624/255, 93.5940/255], [1.0, 1.0, 1.0])\n",
    "stats_bgr_without_norm = A([93.5940, 104.7624, 129.1863], [1.0, 1.0, 1.0])\n",
    "tfms = tfms_from_stats(stats_bgr_without_norm, sz, aug_tfms=aug_tfms, max_zoom=1.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definition of classes\n",
    "with open(path/'names.txt', \"r\") as file:\n",
    "    classes = [line.rstrip().lower() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get data and leaner\n",
    "is_rgb=False \n",
    "do_norm=False\n",
    "\n",
    "#trn_ds_name  = 'comb_xx_nc_actual_sq'             ; new_model_name = 'mt1_vf_nc_actual'\n",
    "#trn_ds_name  = 'comb_xx_two_third_nc_actual_sq'   ; new_model_name = 'mt1_vf_two_third_nc_actual'\n",
    "#trn_ds_name  = 'comb_xx_one_third_nc_actual_sq'   ; new_model_name = 'mt1_vf_one_third_nc_actual'\n",
    "#trn_ds_name  = 'comb_xx_nc_reversed_sq'           ; new_model_name = 'mt1_vf_nc_reversed'\n",
    "#trn_ds_name  = 'comb_xx_two_third_nc_reversed_sq' ; new_model_name = 'mt1_vf_two_third_nc_reversed'\n",
    "#trn_ds_name  = 'comb_xx_one_third_nc_reversed_sq' ; new_model_name = 'mt1_vf_one_third_nc_reversed'\n",
    "\n",
    "#trn_ds_name  = 'comb_xx_nc_actual_wm'             ; new_model_name = 'mt2_vf_nc_actual'\n",
    "#trn_ds_name  = 'comb_xx_two_third_nc_actual_wm'   ; new_model_name = 'mt2_vf_two_third_nc_actual'\n",
    "#trn_ds_name  = 'comb_xx_one_third_nc_actual_wm'   ; new_model_name = 'mt2_vf_one_third_nc_actual'\n",
    "#trn_ds_name  = 'comb_xx_nc_reversed_wm'           ; new_model_name = 'mt2_vf_nc_reversed'\n",
    "#trn_ds_name  = 'comb_xx_two_third_nc_reversed_wm' ; new_model_name = 'mt2_vf_two_third_nc_reversed'\n",
    "#trn_ds_name  = 'comb_xx_one_third_nc_reversed_wm' ; new_model_name = 'mt2_vf_one_third_nc_reversed'\n",
    "\n",
    "\n",
    "val_ds_name  = 'valid'\n",
    "test_ds_name = 'test_crop_224'                                                        \n",
    "data = ImageClassifierData.from_paths(path, tfms=tfms, bs=bs, trn_name=trn_ds_name, \n",
    "                                      val_name=val_ds_name, test_name=test_ds_name,\n",
    "                                      classes=classes, is_rgb=is_rgb, do_norm=do_norm)\n",
    "learner = Learner.from_model_data(vggface(), data, metrics=[accuracy], crit=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Initial Configuration Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Try model without learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.load('vf1')\n",
    "m=learner.model\n",
    "m = to_gpu(m).eval()\n",
    "set_trainable(m, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prep_img(path, fname):\n",
    "    averageImage_rgb = np.array([129.1863, 104.7624, 93.5940])\n",
    "    averageImage_bgr = np.array([93.5940, 104.7624, 129.1863])\n",
    "    im = cv2.imread(f'{path}{fname}')\n",
    "    #im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)            \n",
    "    im = cv2.resize(im, (224,224), interpolation=cv2.INTER_AREA)\n",
    "    im = np.array(im).astype(np.float32)\n",
    "    im = im - averageImage_bgr\n",
    "    im = im.transpose((2,0,1))  # aty between these\n",
    "    #im = np.rollaxis(im,2, 0)  # any between these\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_acc=True\n",
    "folder = 'test/'\n",
    "my_path= f'../data/vggface/{folder}'\n",
    "fnames = os.listdir(my_path)\n",
    "fnames = [f for f in fnames if '.jpg' in f or '.png' in f]\n",
    "y_prob = []\n",
    "y_true = []\n",
    "for f in fnames:\n",
    "    to_append = classes.index(f[:-13]) if is_acc else 0\n",
    "    y_true.append(to_append)\n",
    "    logits = to_np(m(VV(prep_img(my_path, f))))\n",
    "    probs  = to_np(F.softmax(VV(logits)))\n",
    "    y_prob.append(probs[0])\n",
    "accuracy_np(np.array(y_prob), np.array(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_true)):\n",
    "    pred = np.argmax(np.array(y_prob[i]))\n",
    "    print(f'{y_true[i]}: {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Acc with benign data (valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read model\n",
    "learner.load(chosen_model)\n",
    "#data.classes == classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get prediction with valid\n",
    "logits, y_true = learner.predict_with_targs()\n",
    "y_prob = to_np(F.softmax(VV(logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8593333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(accuracy_np(logits, y_true), accuracy_np(y_prob, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Acc with benign data (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read model\n",
    "learner.load('vf_mt1_r06_04')\n",
    "data.classes == classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get ground truth\n",
    "cut = -13 if test_ds_name[-3] != '_' else -16\n",
    "class_indexes = {c: i for i, c in enumerate(data.classes)}\n",
    "filenames = [filepath[filepath.find('/') + 1:] for filepath in data.test_ds.fnames]\n",
    "labels = [f[:cut] for f in filenames]\n",
    "y_true = np.array([class_indexes[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9635416666666666"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model \n",
    "logits = learner.predict(is_test=True)\n",
    "y_prob = to_np(F.softmax(VV(logits)))\n",
    "accuracy_np(y_prob, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Save names with misclassifications less than x=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get misclassifications\n",
    "y_pred = np.argmax(y_prob, 1)\n",
    "my_dict = dict()\n",
    "count = 0\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] not in my_dict:\n",
    "        my_dict[y_true[i]] = 0\n",
    "    if y_true[i] != y_pred[i]:\n",
    "        my_dict[y_true[i]] += 1\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print misclassifications\n",
    "#for i, v in my_dict.items():\n",
    "#    print(f'{i}: {v}')\n",
    "#print(f'Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 64\n"
     ]
    }
   ],
   "source": [
    "# How many classes with less than x misclassifications?\n",
    "x = 2\n",
    "count = 0\n",
    "for i, v in my_dict.items():\n",
    "    if v < x: count += 1\n",
    "print(f'Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 29\n"
     ]
    }
   ],
   "source": [
    "# How many misclassification when each class has less than x misclassiciations\n",
    "count = 0\n",
    "for i, v in my_dict.items():\n",
    "    if v < x: count += v\n",
    "print(f'Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "# Get list of the x names\n",
    "names = []\n",
    "for i, v in my_dict.items():\n",
    "    if v < x: names.append(classes[i])\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(str(path/'names64.txt'), 'w+') as file:\n",
    "    for name in names:\n",
    "        file.write('%s\\n' % name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Acc with adversarial data (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read model\n",
    "learner.load('vf1')\n",
    "data.classes == classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get ground truth\n",
    "class_indexes = {c: i for i, c in enumerate(data.classes)}\n",
    "filenames = [filepath[filepath.find('/') + 1:] for filepath in data.test_ds.fnames]\n",
    "labels = [f[:-13] for f in filenames]\n",
    "y_true = np.array([class_indexes[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model \n",
    "logits = learner.predict(is_test=True)\n",
    "y_prob = to_np(F.softmax(VV(logits)))\n",
    "accuracy_np(y_prob, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ASR with adversarial data (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read model\n",
    "learner.load(chosen_model)\n",
    "data.classes == classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 749\n",
      "Target: 0\n"
     ]
    }
   ],
   "source": [
    "# Get ground truth\n",
    "cut = -13 if test_ds_name[-3] != '_' else -16\n",
    "class_indexes = {c: i for i, c in enumerate(data.classes)}\n",
    "target = class_indexes['a.j._buckley']\n",
    "filenames = [filepath[filepath.find('/') + 1:] for filepath in data.test_ds.fnames]\n",
    "labels   = [f[:cut] for f in filenames]\n",
    "y_true   = np.array([class_indexes[label] for label in labels])\n",
    "to_rm  = np.where(y_true == target)[0]\n",
    "y_target = np.array([target for i in range((len(filenames)-len(to_rm)))])\n",
    "print(f'Number of samples: {len(y_target)}\\nTarget: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026702269692923898"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model \n",
    "log_preds = learner.predict(is_test=True)\n",
    "preds = np.exp(log_preds)\n",
    "preds = np.delete(preds, to_rm, axis=0)\n",
    "accuracy_np(preds, y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Retrain witn NC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 148 ms, sys: 413 ms, total: 561 ms\n",
      "Wall time: 559 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load model\n",
    "learner.precompute=False\n",
    "learner.load('mt1_vf')\n",
    "#learner.load('mt2_vf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984f05a92bbd4820890b919a90091345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      0.64206    0.247928   0.960533  \n",
      "\n",
      "CPU times: user 16.4 s, sys: 4.46 s, total: 20.9 s\n",
      "Wall time: 12.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24792758676701768, 0.9605330599692465]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train one epoch\n",
    "learner.fit(1e-3, n_cycle=1, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 242 ms, sys: 1.04 s, total: 1.28 s\n",
      "Wall time: 7.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(new_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Retrain model: R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 184 ms, sys: 646 ms, total: 830 ms\n",
      "Wall time: 834 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load model\n",
    "learner.load(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5413d782b254aab9eb7a4e12eaa9d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 31/60 [00:18<00:12,  2.41it/s, loss=3.86e+3]CPU times: user 19.6 s, sys: 6.57 s, total: 26.1 s\n",
      "Wall time: 26.3 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# Get learning rate\n",
    "learner.lr_find()\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd6d1994d144c4f99c309c1b19ed8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.310933   0.167242   0.970272  \n",
      "    1      0.197699   0.134326   0.971297                  \n",
      "    2      0.079687   0.13252    0.974372                   \n",
      "    3      0.06885    0.157051   0.968221                   \n",
      "    4      0.048859   0.187288   0.965146                   \n",
      "    5      0.030455   0.147371   0.972322                   \n",
      "    6      0.023586   0.146282   0.974372                   \n",
      "    7      0.04042    0.152518   0.967196                   \n",
      "    8      0.061875   0.162845   0.968734                   \n",
      "    9      0.044588   0.139798   0.971809                   \n",
      "    10     0.030675   0.132125   0.973347                   \n",
      "    11     0.01169    0.125844   0.97796                    \n",
      "    12     0.005338   0.124119   0.977447                    \n",
      "    13     0.002782   0.123788   0.977447                    \n",
      "    14     0.002247   0.123831   0.977447                    \n",
      "    15     0.006343   0.161747   0.972322                    \n",
      "    16     0.014539   0.145712   0.970784                    \n",
      "    17     0.015926   0.153887   0.967709                   \n",
      "    18     0.053973   0.130153   0.971809                   \n",
      "    19     0.035229   0.134342   0.975397                   \n",
      "    20     0.018076   0.145387   0.972834                   \n",
      "    21     0.011232   0.124196   0.97386                    \n",
      "    22     0.007832   0.125294   0.974885                    \n",
      "    23     0.004746   0.126065   0.974885                    \n",
      "    24     0.005095   0.122234   0.977447                    \n",
      "    25     0.003674   0.123374   0.97591                     \n",
      "    26     0.002346   0.121151   0.976422                    \n",
      "    27     0.001185   0.121671   0.976422                    \n",
      "    28     0.002983   0.120971   0.976422                     \n",
      "    29     0.001768   0.120292   0.97591                     \n",
      "    30     0.000902   0.12029    0.97591                      \n",
      "    31     0.006495   0.131439   0.970272                     \n",
      "    32     0.007751   0.122061   0.974372                    \n",
      "    33     0.019621   0.20053    0.961046                    \n",
      "    34     0.020402   0.212991   0.957458                   \n",
      "    35     0.018246   0.159831   0.966171                   \n",
      "    36     0.018826   0.130325   0.972834                   \n",
      "    37     0.020738   0.138779   0.970272                   \n",
      "    38     0.016591   0.134127   0.974372                   \n",
      "    39     0.019639   0.134887   0.974885                    \n",
      "    40     0.012077   0.132029   0.974885                   \n",
      "    41     0.004868   0.126386   0.97591                     \n",
      "    42     0.0022     0.128083   0.97591                     \n",
      "    43     0.000932   0.128041   0.975397                     \n",
      "    44     0.000969   0.133004   0.97591                      \n",
      "    45     0.001324   0.139899   0.974372                     \n",
      "    46     0.007441   0.137202   0.972834                     \n",
      "    47     0.004383   0.124776   0.972322                    \n",
      "    48     0.003104   0.128179   0.972834                    \n",
      "    49     0.001744   0.121336   0.975397                    \n",
      "    50     0.000982   0.12033    0.974372                     \n",
      "    51     0.000644   0.120592   0.974885                     \n",
      "    52     0.002036   0.120966   0.97386                      \n",
      "    53     0.000791   0.121767   0.97386                      \n",
      "    54     0.000314   0.121845   0.973347                     \n",
      "    55     0.000239   0.121838   0.97386                      \n",
      "    56     0.000136   0.121815   0.97386                      \n",
      "    57     0.000604   0.120585   0.97386                      \n",
      "    58     0.00035    0.120515   0.97386                      \n",
      "    59     0.000375   0.120541   0.97386                      \n",
      "    60     0.001057   0.120487   0.97386                      \n",
      "    61     0.000687   0.120483   0.97386                      \n",
      "    62     0.000306   0.120484   0.97386                      \n",
      "\n",
      "CPU times: user 36min 26s, sys: 10min 8s, total: 46min 35s\n",
      "Wall time: 35min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12048417467266878, 0.97385955920041]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 1\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 205 ms, sys: 808 ms, total: 1.01 s\n",
      "Wall time: 6.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5326382dd7df4744a743c18683f871f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.336652   0.144845   0.971297  \n",
      "    1      0.221591   0.14306    0.971809                  \n",
      "    2      0.106562   0.119139   0.975397                  \n",
      "    3      0.113376   0.14648    0.968734                   \n",
      "    4      0.071714   0.141697   0.968221                   \n",
      "    5      0.051521   0.115873   0.976422                   \n",
      "    6      0.034395   0.115552   0.975397                   \n",
      "    7      0.031466   0.220444   0.95797                    \n",
      "    8      0.058222   0.161365   0.966684                   \n",
      "    9      0.049962   0.136971   0.972322                   \n",
      "    10     0.03302    0.14072    0.97386                    \n",
      "    11     0.022824   0.122727   0.975397                   \n",
      "    12     0.015206   0.127107   0.976935                   \n",
      "    13     0.008076   0.128638   0.976935                    \n",
      "    14     0.009891   0.128392   0.976422                    \n",
      "    15     0.03227    0.140206   0.970272                    \n",
      "    16     0.060467   0.154304   0.968734                   \n",
      "    17     0.058362   0.124013   0.969759                   \n",
      "    18     0.051844   0.110338   0.97591                    \n",
      "    19     0.036997   0.122109   0.975397                   \n",
      "    20     0.017643   0.120249   0.976935                   \n",
      "    21     0.016971   0.108767   0.978473                   \n",
      "    22     0.012002   0.119023   0.972834                   \n",
      "    23     0.007242   0.109807   0.97796                     \n",
      "    24     0.007006   0.114879   0.976422                    \n",
      "    25     0.004276   0.118845   0.974885                    \n",
      "    26     0.002557   0.119607   0.974885                    \n",
      "    27     0.003019   0.118801   0.975397                    \n",
      "    28     0.002752   0.116734   0.97591                     \n",
      "    29     0.002467   0.115867   0.97591                     \n",
      "    30     0.001502   0.115835   0.97591                     \n",
      "    31     0.003866   0.128284   0.97386                     \n",
      "    32     0.006948   0.123942   0.97591                     \n",
      "    33     0.002971   0.126752   0.98001                     \n",
      "    34     0.019051   0.129163   0.972322                    \n",
      "    35     0.013365   0.127255   0.976422                   \n",
      "    36     0.018535   0.146042   0.971297                   \n",
      "    37     0.015826   0.144189   0.971809                   \n",
      "    38     0.008456   0.143975   0.974372                    \n",
      "    39     0.011216   0.123675   0.97386                     \n",
      "    40     0.01648    0.164893   0.967709                    \n",
      "    41     0.0228     0.118788   0.973347                   \n",
      "    42     0.011685   0.124478   0.974885                   \n",
      "    43     0.004855   0.124884   0.976935                    \n",
      "    44     0.003009   0.106791   0.981035                    \n",
      "    45     0.001715   0.115476   0.978473                    \n",
      "    46     0.001386   0.123239   0.97591                     \n",
      "    47     0.002449   0.11942    0.976935                    \n",
      "    48     0.001161   0.117522   0.976422                    \n",
      "    49     0.00058    0.117397   0.976422                     \n",
      "    50     0.00033    0.117773   0.97591                      \n",
      "    51     0.00382    0.121885   0.976422                     \n",
      "    52     0.001436   0.123144   0.977447                    \n",
      "    53     0.003646   0.119469   0.97796                      \n",
      "    54     0.00347    0.117797   0.97796                     \n",
      "    55     0.001295   0.118068   0.97796                     \n",
      "    56     0.00055    0.118178   0.97796                      \n",
      "    57     0.000274   0.118323   0.97796                      \n",
      "    58     0.000228   0.118338   0.97796                      \n",
      "    59     0.000564   0.118213   0.97796                      \n",
      "    60     0.000778   0.11844    0.97796                      \n",
      "    61     0.001743   0.118436   0.97796                      \n",
      "    62     0.000673   0.118432   0.97796                      \n",
      "\n",
      "CPU times: user 37min 41s, sys: 10min 59s, total: 48min 41s\n",
      "Wall time: 35min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11843151608715899, 0.9779600205023065]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 2\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 204 ms, sys: 899 ms, total: 1.1 s\n",
      "Wall time: 7.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Re-train 3\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r_03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Re-train 4\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r_04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Re-train 5\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r_05')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Retrain model: R00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 187 ms, sys: 887 ms, total: 1.07 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load model\n",
    "learner.load(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8d001ba9c84ddcaaf9041d5bd505a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 59/120 [00:27<00:22,  2.76it/s, loss=5.87e+6]CPU times: user 31.1 s, sys: 10.9 s, total: 42 s\n",
      "Wall time: 37.3 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# Get learning rate\n",
    "learner.lr_find()\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb4cb36b08841e6a420ddb4d628bba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      4.982203   3.839822   0.024603  \n",
      "    1      4.091374   4.154923   0.02614                    \n",
      "    2      3.860683   3.72485    0.026653                   \n",
      "    3      3.883498   4.520848   0.025628                   \n",
      "    4      3.827436   3.944925   0.025115                   \n",
      "    5      3.792344   3.745709   0.031266                   \n",
      "    6      3.777501   3.684365   0.037929                   \n",
      "    7      3.838943   3.978979   0.030753                   \n",
      "    8      3.835559   3.969582   0.026653                   \n",
      "    9      3.798313   3.845455   0.031266                   \n",
      "    10     3.776709   3.792019   0.025115                   \n",
      "    11     3.765511   3.71736    0.035366                   \n",
      "    12     3.757667   3.647131   0.040492                   \n",
      "    13     3.736211   3.6342     0.051256                   \n",
      "    14     3.733213   3.632795   0.053819                   \n",
      "    15     3.793265   3.960359   0.02614                    \n",
      "    16     3.791617   3.919087   0.032291                   \n",
      "    17     3.779805   3.892281   0.027678                   \n",
      "    18     3.772764   3.832365   0.036904                   \n",
      "    19     3.771302   3.753391   0.036392                   \n",
      "    20     3.76932    3.68476    0.063557                   \n",
      "    21     3.754078   3.715354   0.027678                   \n",
      "    22     3.763655   3.662915   0.055356                   \n",
      "    23     3.754562   3.619408   0.041005                   \n",
      "    24     3.744319   3.640935   0.045618                   \n",
      "    25     3.733659   3.607602   0.065607                   \n",
      "    26     3.735864   3.587673   0.054844                   \n",
      "    27     3.729589   3.589298   0.095848                   \n",
      "    28     3.732863   3.588877   0.081497                   \n",
      "    29     3.718755   3.594695   0.079446                   \n",
      "    30     3.72075    3.594912   0.074321                   \n",
      "    31     3.762205   3.760246   0.038442                   \n",
      "    32     3.774398   3.659278   0.055869                   \n",
      "    33     3.768106   3.716337   0.060482                   \n",
      "    34     3.771048   3.759317   0.035366                   \n",
      "    35     3.761718   3.703602   0.065095                   \n",
      "    36     3.757613   3.664724   0.055869                   \n",
      "    37     3.750402   3.684331   0.027166                   \n",
      "    38     3.759239   3.628081   0.043055                   \n",
      "    39     3.755049   3.692701   0.036392                   \n",
      "    40     3.744949   3.669914   0.055356                   \n",
      "    41     3.748867   3.634639   0.065095                   \n",
      "    42     3.748274   3.646423   0.04408                    \n",
      "    43     3.743861   3.666087   0.035879                   \n",
      "    44     3.736097   3.638746   0.084059                   \n",
      "    45     3.738986   3.630172   0.069195                   \n",
      "    46     3.738296   3.618635   0.056381                   \n",
      "    47     3.727187   3.648126   0.035366                   \n",
      "    48     3.738828   3.597519   0.074321                   \n",
      "    49     3.728906   3.612653   0.053819                   \n",
      "    50     3.727053   3.612314   0.059969                   \n",
      "    51     3.720421   3.58755    0.059969                   \n",
      "    52     3.72204    3.586652   0.090723                   \n",
      "    53     3.721173   3.587204   0.047668                   \n",
      "    54     3.722179   3.579064   0.089185                   \n",
      "    55     3.715941   3.578804   0.082009                   \n",
      "    56     3.716193   3.580434   0.104049                   \n",
      "    57     3.71318    3.580544   0.1143                     \n",
      "    58     3.714594   3.580752   0.119426                   \n",
      "    59     3.708429   3.58273    0.11225                    \n",
      "    60     3.711968   3.581168   0.114813                   \n",
      "    61     3.705208   3.581743   0.11225                    \n",
      "    62     3.713243   3.581755   0.11225                    \n",
      "CPU times: user 1h 9min 27s, sys: 16min 54s, total: 1h 26min 21s\n",
      "Wall time: 1h 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5817550852749664, 0.11225012810886487]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 1\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 142 ms, sys: 792 ms, total: 934 ms\n",
      "Wall time: 6.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r00_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde238aecab0410a94d62248e6b56fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      3.732051   3.609282   0.075859  \n",
      "    1      3.741863   3.616264   0.079446                   \n",
      "    2      3.720078   3.605496   0.080472                   \n",
      "    3      3.738799   3.651645   0.083034                   \n",
      "    4      3.738768   3.65069    0.034341                   \n",
      "    5      3.723791   3.587321   0.116351                   \n",
      "    6      3.711772   3.591009   0.060482                   \n",
      "    7      3.740318   3.660487   0.027678                   \n",
      "    8      3.741838   3.66911    0.042542                   \n",
      "    9      3.740525   3.619974   0.079446                   \n",
      "    10     3.737581   3.63484    0.035366                   \n",
      "    11     3.731037   3.582623   0.077396                   \n",
      "    12     3.723014   3.58062    0.122501                   \n",
      "    13     3.715808   3.580566   0.098411                   \n",
      "    14     3.71285    3.581862   0.098924                   \n",
      "    15     3.734676   3.666939   0.071246                   \n",
      "    16     3.741795   3.646784   0.072271                   \n",
      "    17     3.739825   3.664783   0.050231                   \n",
      "    18     3.744797   3.62007    0.044593                   \n",
      "    19     3.732125   3.667695   0.051256                   \n",
      "    20     3.735055   3.618936   0.078421                   \n",
      "    21     3.729153   3.625143   0.047668                   \n",
      "    22     3.728656   3.613317   0.060994                   \n",
      "    23     3.72852    3.592756   0.073808                   \n",
      "    24     3.721823   3.589254   0.097386                   \n",
      "    25     3.710095   3.595836   0.052281                   \n",
      "    26     3.716782   3.586026   0.069708                   \n",
      "    27     3.718213   3.585601   0.079446                   \n",
      "    28     3.714632   3.584856   0.074833                   \n",
      "    29     3.71231    3.585943   0.072271                   \n",
      "    30     3.710115   3.585414   0.072783                   \n",
      "    31     3.737332   3.668166   0.052281                   \n",
      "    32     3.738485   3.638672   0.073808                   \n",
      "    33     3.741747   3.630166   0.067145                   \n",
      "    34     3.735737   3.683333   0.028191                   \n",
      "    35     3.739487   3.612739   0.10815                    \n",
      "    36     3.738081   3.662945   0.032291                   \n",
      "    37     3.736764   3.637167   0.071246                   \n",
      "    38     3.730324   3.667932   0.029216                   \n",
      "    39     3.727267   3.664362   0.027166                   \n",
      "    40     3.731624   3.634583   0.068683                   \n",
      "    41     3.731325   3.635068   0.023065                   \n",
      "    42     3.735198   3.633971   0.032804                   \n",
      "    43     3.729797   3.618487   0.033829                   \n",
      "    44     3.732757   3.609493   0.053306                   \n",
      "    45     3.724743   3.61462    0.065607                   \n",
      "    46     3.72872    3.598026   0.111738                   \n",
      "    47     3.723502   3.611293   0.028703                   \n",
      "    48     3.716826   3.614288   0.046643                   \n",
      "    49     3.718196   3.603692   0.075346                   \n",
      "    50     3.713945   3.614597   0.049718                   \n",
      "    51     3.719667   3.599612   0.067145                   \n",
      "    52     3.713494   3.601122   0.086622                   \n",
      "    53     3.712682   3.595988   0.06612                    \n",
      "    54     3.711474   3.598142   0.073808                   \n",
      "    55     3.707994   3.601477   0.063045                   \n",
      "    56     3.712204   3.597598   0.078421                   \n",
      "    57     3.712222   3.597609   0.078421                   \n",
      "    58     3.707248   3.597796   0.079959                   \n",
      "    59     3.703115   3.598556   0.078421                  \n",
      "    60     3.702796   3.598487   0.077396                   \n",
      "    61     3.705367   3.59868    0.077396                   \n",
      "    62     3.702148   3.5986     0.076884                   \n",
      "CPU times: user 1h 11min 9s, sys: 17min 39s, total: 1h 28min 49s\n",
      "Wall time: 1h 2min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.598599666451748, 0.07688364913560133]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 2\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 138 ms, sys: 805 ms, total: 942 ms\n",
      "Wall time: 6.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r00_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c27e63d36b748d498414a04dd8db34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      3.724171   3.612345   0.061507  \n",
      "    1      3.730314   3.643776   0.034854                   \n",
      "    2      3.721021   3.607971   0.067145                   \n",
      "    3      3.724476   3.630648   0.060994                   \n",
      "    4      3.723954   3.626842   0.032291                   \n",
      "    5      3.713905   3.602684   0.062019                   \n",
      "    6      3.711956   3.601479   0.062019                   \n",
      "    7      3.730956   3.659972   0.031779                   \n",
      "    8      3.73326    3.654948   0.06817                    \n",
      "    9      3.727629   3.645543   0.08611                    \n",
      "    10     3.722414   3.631113   0.057919                   \n",
      "    11     3.722812   3.60825    0.043055                   \n",
      "    12     3.713075   3.603175   0.099949                   \n",
      "    13     3.712688   3.601042   0.123526                   \n",
      "    14     3.707909   3.600808   0.115325                   \n",
      "    15     3.73086    3.635527   0.062532                   \n",
      "    16     3.729418   3.658183   0.044593                   \n",
      "    17     3.732983   3.667732   0.062532                   \n",
      "    18     3.724755   3.634286   0.060482                   \n",
      "    19     3.726373   3.628088   0.067658                   \n",
      "    20     3.720836   3.655354   0.037929                   \n",
      "    21     3.722657   3.643729   0.059457                   \n",
      "    22     3.723971   3.624969   0.037417                   \n",
      "    23     3.722832   3.613947   0.091235                   \n",
      "    24     3.714212   3.605233   0.096873                   \n",
      "    25     3.717007   3.598171   0.097899                   \n",
      "    26     3.712887   3.599156   0.109687                   \n",
      "    27     3.714183   3.600323   0.109175                   \n",
      "    28     3.707864   3.602348   0.117376                   \n",
      "    29     3.707129   3.602022   0.115325                   \n",
      "    30     3.703336   3.602108   0.115325                  \n",
      "    31     3.722453   3.644178   0.09021                    \n",
      "    32     3.728899   3.674548   0.050743                   \n",
      "    33     3.729934   3.664821   0.051768                   \n",
      "    34     3.733041   3.628575   0.065607                   \n",
      "    35     3.729472   3.640709   0.083547                   \n",
      "    36     3.730725   3.666495   0.052281                   \n",
      "    37     3.723342   3.668094   0.035879                   \n",
      "    38     3.7215     3.65242    0.037417                   \n",
      "    39     3.72716    3.652927   0.067145                   \n",
      "    40     3.727396   3.631279   0.045105                   \n",
      "    41     3.728069   3.638781   0.084059                   \n",
      "    42     3.716726   3.65225    0.04613                    \n",
      "    43     3.719895   3.644032   0.036392                   \n",
      "    44     3.720346   3.635423   0.050231                   \n",
      "    45     3.719935   3.630806   0.068683                   \n",
      "    46     3.720989   3.624056   0.062532                   \n",
      "    47     3.717673   3.627745   0.06407                    \n",
      "    48     3.715113   3.633692   0.083547                   \n",
      "    49     3.719161   3.628843   0.056381                   \n",
      "    50     3.716708   3.627593   0.066632                   \n",
      "    51     3.714951   3.622734   0.041005                   \n",
      "    52     3.71356    3.621958   0.043055                   \n",
      "    53     3.711987   3.622085   0.075859                   \n",
      "    54     3.717138   3.621481   0.059457                   \n",
      "    55     3.708832   3.62242    0.084059                   \n",
      "    56     3.708211   3.621112   0.076371                   \n",
      "    57     3.705077   3.621957   0.095336                   \n",
      "    58     3.705421   3.622219   0.09226                    \n",
      "    59     3.704815   3.622582   0.091748                   \n",
      "    60     3.703463   3.622696   0.089698                  \n",
      "    61     3.707575   3.622656   0.093285                   \n",
      "    62     3.704752   3.622622   0.09226                    \n",
      "CPU times: user 1h 9min 50s, sys: 17min 17s, total: 1h 27min 8s\n",
      "Wall time: 1h 1min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.622622162791046, 0.09226037909409011]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 3\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 755 ms, total: 913 ms\n",
      "Wall time: 6.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r00_03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecb2479c5ed45fda8a16367222efffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      3.713705   3.627797   0.053306  \n",
      "    1      3.728044   3.639181   0.037417                   \n",
      "    2      3.715676   3.623405   0.072271                   \n",
      "    3      3.725496   3.64756    0.06612                    \n",
      "    4      3.720508   3.647885   0.041005                   \n",
      "    5      3.716716   3.631605   0.085597                   \n",
      "    6      3.708637   3.632075   0.066632                   \n",
      "    7      3.723842   3.663572   0.034341                   \n",
      "    8      3.719977   3.682228   0.027166                   \n",
      "    9      3.721092   3.653113   0.047668                   \n",
      "    10     3.718845   3.65151    0.032804                   \n",
      "    11     3.720829   3.638372   0.062532                   \n",
      "    12     3.715177   3.631984   0.084572                   \n",
      "    13     3.707033   3.629932   0.078934                   \n",
      "    14     3.703827   3.629861   0.086622                   \n",
      "    15     3.723625   3.659619   0.041517                   \n",
      "    16     3.728437   3.67138    0.056381                   \n",
      "    17     3.722855   3.654635   0.038954                   \n",
      "    18     3.72163    3.680089   0.04818                    \n",
      "    19     3.724406   3.637704   0.055356                   \n",
      "    20     3.722217   3.643003   0.071246                   \n",
      "    21     3.7244     3.640268   0.064582                   \n",
      "    22     3.719897   3.641118   0.067658                   \n",
      "    23     3.713423   3.629525   0.074321                   \n",
      "    24     3.714574   3.634074   0.051768                   \n",
      "    25     3.709848   3.631611   0.096873                   \n",
      "    26     3.71171    3.631323   0.091235                   \n",
      "    27     3.712695   3.629607   0.102512                   \n",
      "    28     3.706854   3.62962    0.106099                   \n",
      "    29     3.703563   3.630516   0.100461                   \n",
      "    30     3.70033    3.630614   0.103024                  \n",
      "    31     3.718718   3.687134   0.038954                   \n",
      "    32     3.725948   3.673593   0.028191                   \n",
      "    33     3.727008   3.677948   0.037417                   \n",
      "    34     3.725432   3.669301   0.040492                   \n",
      "    35     3.723024   3.66755    0.051256                   \n",
      "    36     3.726869   3.663701   0.048693                   \n",
      "    37     3.726432   3.676006   0.036392                   \n",
      "    38     3.71948    3.674586   0.055869                   \n",
      "    39     3.727247   3.65333    0.054331                   \n",
      "    40     3.723654   3.661977   0.025115                   \n",
      "    41     3.724149   3.652408   0.073808                   \n",
      "    42     3.72393    3.662353   0.043567                   \n",
      "    43     3.721581   3.656222   0.059457                   \n",
      "    44     3.715077   3.648895   0.054844                   \n",
      "    45     3.716262   3.649006   0.086622                   \n",
      "    46     3.714274   3.649118   0.04408                    \n",
      "    47     3.716928   3.644464   0.064582                   \n",
      "    48     3.714877   3.643115   0.04613                    \n",
      "    49     3.711555   3.64101    0.074321                   \n",
      "    50     3.712251   3.636778   0.056381                   \n",
      "    51     3.71162    3.641546   0.04203                    \n",
      "    52     3.708747   3.641418   0.078421                   \n",
      "    53     3.711378   3.637948   0.068683                   \n",
      "    54     3.712608   3.637203   0.074321                   \n",
      "    55     3.702292   3.639242   0.075346                  \n",
      "    56     3.703146   3.638798   0.082009                  \n",
      "    57     3.704023   3.638421   0.079446                  \n",
      "    58     3.703168   3.637803   0.08611                   \n",
      "    59     3.701171   3.638635   0.085597                  \n",
      "    60     3.699916   3.638372   0.083547                  \n",
      "    61     3.703031   3.638403   0.081497                  \n",
      "    62     3.701229   3.63839    0.080984                  \n",
      "CPU times: user 1h 9min 45s, sys: 17min 26s, total: 1h 27min 11s\n",
      "Wall time: 1h 1min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.638390379523938, 0.08098410985703226]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 4\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 ms, sys: 794 ms, total: 933 ms\n",
      "Wall time: 7.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r00_04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Retrain model: R01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 188 ms, total: 308 ms\n",
      "Wall time: 305 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load model\n",
    "learner.load(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817a9e802fa34002a262ee6ca1d2beaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 83/180 [00:52<00:59,  1.62it/s, loss=1.22e+7]CPU times: user 1min 14s, sys: 9.64 s, total: 1min 24s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# Get learning rate\n",
    "learner.lr_find()\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c273464d9f4241a180ab28c5d5de5761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=31, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      4.636599   4.596685   0.284375  \n",
      "    1      4.418875   4.386226   0.322396                   \n",
      "    2      4.285069   4.307896   0.392708                   \n",
      "    3      4.348503   4.456401   0.347917                   \n",
      "    4      4.298245   4.332884   0.429167                   \n",
      "    5      4.274473   4.260138   0.435417                   \n",
      "    6      4.239177   4.219545   0.453646                   \n",
      "    7      4.290592   4.261129   0.339062                   \n",
      "    8      4.285003   4.419042   0.427083                   \n",
      "    9      4.278859   4.326741   0.468229                   \n",
      "    10     4.255549   4.371138   0.440104                   \n",
      "    11     4.240216   4.184176   0.455729                   \n",
      "    12     4.229167   4.206433   0.451042                   \n",
      "    13     4.212822   4.186383   0.480208                   \n",
      "    14     4.199769   4.172787   0.477604                   \n",
      "    15     4.268383   4.342992   0.403646                   \n",
      "    16     4.263118   4.350402   0.43125                    \n",
      "    17     4.254866   4.308127   0.350521                   \n",
      "    18     4.25313    4.239323   0.352604                   \n",
      "    19     4.237981   4.307495   0.410417                   \n",
      "    20     4.235873   4.229108   0.355729                   \n",
      "    21     4.234988   4.212624   0.371354                   \n",
      "    22     4.219603   4.217214   0.375521                   \n",
      "    23     4.220998   4.181145   0.386458                   \n",
      "    24     4.211634   4.157937   0.432812                   \n",
      "    25     4.210614   4.170484   0.389583                   \n",
      "    26     4.202482   4.144464   0.411458                  \n",
      "    27     4.200712   4.128472   0.401042                   \n",
      "    28     4.193011   4.108791   0.414062                   \n",
      "    29     4.18917    4.105165   0.414583                   \n",
      "    30     4.188371   4.105287   0.413542                   \n",
      "CPU times: user 1h 18min 43s, sys: 10min 6s, total: 1h 28min 49s\n",
      "Wall time: 1h 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.1052865823109945, 0.41354166666666664]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 1\n",
    "learner.fit(1e-3, n_cycle=5, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 396 ms, total: 604 ms\n",
      "Wall time: 7.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r01_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824535ee9ac84515a18158091f37345e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=31, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      4.214626   4.132665   0.434375  \n",
      "    1      4.22135    4.181423   0.415625                   \n",
      "    2      4.199512   4.126389   0.402083                   \n",
      "    3      4.232297   4.271313   0.344271                   \n",
      "    4      4.213319   4.229418   0.426562                   \n",
      "    5      4.207534   4.167228   0.424479                   \n",
      "    6      4.203226   4.151774   0.418229                   \n",
      "    7      4.228924   4.306962   0.390104                   \n",
      "    8      4.224768   4.228822   0.452604                   \n",
      "    9      4.22043    4.157352   0.369792                   \n",
      "    10     4.220324   4.197249   0.434896                   \n",
      "    11     4.202478   4.120993   0.39375                    \n",
      "    12     4.205028   4.161148   0.43125                    \n",
      "    13     4.196036   4.150726   0.447917                  \n",
      "    14     4.197094   4.135299   0.445312                   \n",
      "    15     4.2279     4.331955   0.388021                   \n",
      "    16     4.228106   4.224109   0.367708                   \n",
      "    17     4.219716   4.182314   0.425                      \n",
      "    18     4.220444   4.283201   0.380208                   \n",
      "    19     4.220403   4.249492   0.365625                   \n",
      "    20     4.213426   4.174187   0.332292                   \n",
      "    21     4.220512   4.163106   0.399479                   \n",
      "    22     4.201046   4.099435   0.356771                   \n",
      "    23     4.210412   4.223572   0.416146                   \n",
      "    24     4.197892   4.204847   0.434375                   \n",
      "    25     4.191597   4.16276    0.434896                   \n",
      "    26     4.191284   4.177112   0.415104                   \n",
      "    27     4.192359   4.182732   0.426042                   \n",
      "    28     4.186935   4.170386   0.420312                   \n",
      "    29     4.185874   4.171037   0.421354                   \n",
      "    30     4.183863   4.170974   0.421354                   \n",
      "CPU times: user 1h 18min 14s, sys: 10min 34s, total: 1h 28min 48s\n",
      "Wall time: 1h 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.170974151293437, 0.42135416666666664]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 2\n",
    "learner.fit(1e-3, n_cycle=5, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 164 ms, sys: 420 ms, total: 584 ms\n",
      "Wall time: 7.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r01_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67eb6fe540ed44f3b57f2ca9bbee18fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      4.208363   4.230254   0.3625    \n",
      "    1      4.207928   4.23546    0.330208                   \n",
      "    2      4.186527   4.177003   0.419271                   \n",
      "    3      4.215286   4.217924   0.247396                   \n",
      "    4      4.211097   4.20093    0.385938                   \n",
      "    5      4.194867   4.180232   0.4125                     \n",
      "    6      4.191721   4.183273   0.411979                   \n",
      "    7      4.214997   4.303118   0.286458                   \n",
      "    8      4.219296   4.32127    0.414062                   \n",
      "    9      4.21295    4.352031   0.391146                   \n",
      "    10     4.199297   4.239551   0.370833                  \n",
      "    11     4.196257   4.226344   0.383854                   \n",
      "    12     4.193975   4.229314   0.393229                   \n",
      "    13     4.189537   4.217874   0.399479                   \n",
      "    14     4.185496   4.212921   0.398438                   \n",
      "    15     4.21439    4.248233   0.315625                   \n",
      "    16     4.209213   4.270741   0.29375                    \n",
      "    17     4.213007   4.282579   0.304688                   \n",
      "    18     4.217632   4.332377   0.369792                   \n",
      "    19     4.211559   4.253628   0.348438                   \n",
      "    20     4.205271   4.271862   0.284375                   \n",
      "    21     4.203715   4.269833   0.331771                   \n",
      "    22     4.198802   4.296977   0.413021                  \n",
      "    23     4.197036   4.305497   0.342188                   \n",
      "    24     4.195934   4.300175   0.382812                   \n",
      "    25     4.189227   4.237163   0.395833                   \n",
      "    26     4.184028   4.236834   0.411458                   \n",
      "    27     4.188774   4.25038    0.417188                   \n",
      "    28     4.181908   4.237837   0.416667                   \n",
      "    29     4.185243   4.2368     0.411979                   \n",
      "    30     4.177578   4.239248   0.409375                   \n",
      "    31     4.208208   4.400237   0.345312                   \n",
      "    32     4.208582   4.270346   0.317188                   \n",
      "    33     4.20773    4.289012   0.292708                   \n",
      "    34     4.209261   4.313881   0.320833                   \n",
      "    35     4.210398   4.358205   0.363021                   \n",
      "    36     4.208675   4.343633   0.282292                   \n",
      "    37     4.206859   4.292534   0.367188                   \n",
      "    38     4.205482   4.307835   0.386979                   \n",
      "    39     4.202114   4.308924   0.334896                  \n",
      "    40     4.20036    4.266808   0.288542                   \n",
      "    41     4.198562   4.296544   0.344792                   \n",
      "    42     4.198668   4.270212   0.307292                  \n",
      "    43     4.199209   4.309406   0.321354                  \n",
      "    44     4.200317   4.359923   0.408854                   \n",
      "    45     4.196314   4.286896   0.368229                  \n",
      "    46     4.197822   4.318025   0.408854                  \n",
      "    47     4.192626   4.266391   0.384375                   \n",
      "    48     4.19113    4.325151   0.372396                   \n",
      "    49     4.190861   4.298719   0.371354                   \n",
      "    50     4.190637   4.300107   0.365104                   \n",
      "    51     4.187053   4.277269   0.399479                   \n",
      "    52     4.187963   4.286716   0.398958                   \n",
      "    53     4.183818   4.264219   0.396875                   \n",
      "    54     4.182159   4.264879   0.413542                   \n",
      "    55     4.179767   4.25689    0.41875                    \n",
      "    56     4.181493   4.268203   0.416146                   \n",
      "    57     4.18159    4.264582   0.416146                   \n",
      "    58     4.174399   4.234453   0.417708                   \n",
      "    59     4.180204   4.247378   0.419792                   \n",
      "    60     4.179393   4.248788   0.423958                   \n",
      "    61     4.175605   4.249559   0.422396                   \n",
      "    62     4.179039   4.249407   0.421354                   \n",
      "CPU times: user 2h 39min 19s, sys: 21min 47s, total: 3h 1min 6s\n",
      "Wall time: 2h 3min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.249407362937927, 0.42135416666666664]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 3\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 192 ms, sys: 396 ms, total: 588 ms\n",
      "Wall time: 7.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r01_03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f99359b77f4eda968406ac413ce90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      4.185092   4.283134   0.43125   \n",
      "    1      4.184428   4.295775   0.378646                 \n",
      "    2      4.177609   4.250218   0.401042                 \n",
      "    3      4.187519   4.316703   0.417188                 \n",
      "    4      4.186551   4.265054   0.4                      \n",
      "    5      4.184753   4.283511   0.421875                 \n",
      "    6      4.17621    4.256412   0.409375                 \n",
      "    7      4.185842   4.307316   0.374479                 \n",
      "    8      4.186456   4.280378   0.419792                 \n",
      "    9      4.183317   4.268284   0.444271                 \n",
      "    10     4.181518   4.27678    0.404688                 \n",
      "    11     4.182645   4.272388   0.403646                 \n",
      "    12     4.179543   4.252351   0.41875                  \n",
      "    13     4.177184   4.240656   0.423438                 \n",
      "    14     4.173395   4.238206   0.425521                 \n",
      "    15     4.184008   4.289621   0.381771                 \n",
      "    16     4.186642   4.293258   0.402083                 \n",
      "    17     4.185502   4.249665   0.402083                 \n",
      "    18     4.184454   4.273546   0.415625                 \n",
      "    19     4.182013   4.267813   0.376042                 \n",
      "    20     4.183813   4.275291   0.38125                  \n",
      "    21     4.184163   4.261983   0.407813                 \n",
      "    22     4.181037   4.242381   0.433854                 \n",
      "    23     4.178914   4.248719   0.426042                 \n",
      "    24     4.177731   4.241169   0.451042                 \n",
      "    25     4.176712   4.238867   0.433854                 \n",
      "    26     4.173633   4.214482   0.4375                   \n",
      "    27     4.17666    4.224439   0.425                    \n",
      "    28     4.172571   4.219574   0.432292                 \n",
      "    29     4.173259   4.216468   0.429167                 \n",
      "    30     4.173049   4.216583   0.429167                 \n",
      "    31     4.185319   4.289424   0.386458                 \n",
      "    32     4.18564    4.26738    0.423438                 \n",
      "    33     4.185098   4.246208   0.370833                 \n",
      "    34     4.185226   4.287014   0.405729                 \n",
      "    35     4.184079   4.280769   0.3875                   \n",
      "    36     4.182507   4.214872   0.4375                   \n",
      "    37     4.184063   4.288683   0.450521                 \n",
      "    38     4.18564    4.292018   0.433333                 \n",
      "    39     4.181338   4.249107   0.421354                 \n",
      "    40     4.183574   4.262118   0.428125                 \n",
      "    41     4.179783   4.239276   0.419271                 \n",
      "    42     4.179743   4.236908   0.420833                 \n",
      "    43     4.177464   4.25188    0.417188                 \n",
      "    44     4.179136   4.240655   0.434375                 \n",
      "    45     4.181115   4.263933   0.406771                 \n",
      "    46     4.176077   4.232311   0.438021                 \n",
      "    47     4.178431   4.255992   0.438021                 \n",
      "    48     4.178756   4.256245   0.422396                 \n",
      "    49     4.177476   4.237444   0.415104                 \n",
      "    50     4.173085   4.2135     0.426042                 \n",
      "    51     4.173685   4.224233   0.429688                 \n",
      "    52     4.173412   4.222257   0.43125                  \n",
      "    53     4.171123   4.20529    0.426563                 \n",
      "    54     4.170207   4.203608   0.434896                 \n",
      "    55     4.172531   4.218207   0.432292                 \n",
      "    56     4.171943   4.21507    0.436458                 \n",
      "    57     4.173975   4.217648   0.428646                 \n",
      "    58     4.172431   4.212595   0.429167                 \n",
      "    59     4.171299   4.210076   0.422917                 \n",
      "    60     4.171922   4.210593   0.426042                 \n",
      "    61     4.167466   4.209879   0.426042                 \n",
      "    62     4.16997    4.209723   0.425521                 \n",
      "\n",
      "CPU times: user 1h 14min 26s, sys: 21min 13s, total: 1h 35min 40s\n",
      "Wall time: 52min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 4\n",
    "learner.load(chosen_model+'_r01_03')\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 182 ms, sys: 656 ms, total: 838 ms\n",
      "Wall time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r01_04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2f54faa64149abb9c316f7c18d3d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      4.180429   4.257131   0.408854  \n",
      "    1      4.179033   4.233976   0.423958                 \n",
      "    2      4.172566   4.225508   0.4375                   \n",
      "    3      4.177851   4.25257    0.392708                 \n",
      "    4      4.179567   4.250386   0.434896                 \n",
      "    5      4.173584   4.222015   0.425521                 \n",
      "    6      4.169018   4.221875   0.419271                 \n",
      "    7      4.178464   4.241327   0.402604                 \n",
      "    8      4.181159   4.253494   0.400521                 \n",
      "    9      4.182641   4.253715   0.428125                 \n",
      "    10     4.182305   4.253529   0.425                    \n",
      "    11     4.178489   4.241493   0.436979                 \n",
      "    12     4.174      4.220781   0.436979                 \n",
      "    13     4.170808   4.206117   0.436458                 \n",
      "    14     4.168471   4.204604   0.438542                 \n",
      "    15     4.181164   4.281306   0.391667                 \n",
      "    16     4.182398   4.272122   0.364063                 \n",
      "    17     4.183267   4.247329   0.395313                 \n",
      "    18     4.181892   4.249684   0.426042                 \n",
      "    19     4.182305   4.268711   0.4125                   \n",
      "    20     4.17882    4.239549   0.408333                 \n",
      "    21     4.176819   4.208805   0.385417                 \n",
      "    22     4.175625   4.248895   0.4                      \n",
      "    23     4.175413   4.243528   0.415104                 \n",
      "    24     4.172734   4.221895   0.4375                   \n",
      "    25     4.176002   4.247425   0.439063                 \n",
      "    26     4.175032   4.227503   0.432292                 \n",
      "    27     4.17238    4.21831    0.430729                 \n",
      "    28     4.171906   4.214274   0.438021                 \n",
      "    29     4.170281   4.213237   0.441667                 \n",
      "    30     4.171776   4.213058   0.439583                 \n",
      "    31     4.180643   4.250269   0.388021                 \n",
      "    32     4.182457   4.294696   0.404167                 \n",
      "    33     4.18532    4.284606   0.356771                 \n",
      "    34     4.183637   4.277658   0.404688                 \n",
      "    35     4.184225   4.26789    0.430208                 \n",
      "    36     4.180979   4.272143   0.426042                 \n",
      "    37     4.183282   4.278329   0.392188                 \n",
      "    38     4.181622   4.267605   0.398958                 \n",
      "    39     4.179713   4.258293   0.4                      \n",
      "    40     4.179321   4.292024   0.394792                 \n",
      "    41     4.179522   4.278783   0.380729                 \n",
      "    42     4.179318   4.274996   0.395833                 \n",
      "    43     4.178494   4.257228   0.407813                 \n",
      "    44     4.177923   4.295056   0.405208                 \n",
      "    45     4.177786   4.271917   0.397396                 \n",
      "    46     4.178313   4.293567   0.395833                 \n",
      "    47     4.178681   4.284078   0.407292                 \n",
      "    48     4.177032   4.265405   0.423438                 \n",
      "    49     4.175289   4.260662   0.403646                 \n",
      "    50     4.174357   4.264086   0.410417                 \n",
      "    51     4.173501   4.252209   0.405208                 \n",
      "    52     4.172016   4.24562    0.399479                 \n",
      "    53     4.174052   4.253915   0.402604                 \n",
      "    54     4.168665   4.227658   0.402083                 \n",
      "    55     4.171489   4.234235   0.408333                 \n",
      "    56     4.170916   4.236042   0.413021                 \n",
      "    57     4.169713   4.235704   0.407813                 \n",
      "    58     4.1683     4.22975    0.413542                 \n",
      "    59     4.170878   4.232891   0.410938                 \n",
      "    60     4.17       4.233087   0.4125                   \n",
      "    61     4.16987    4.233094   0.411458                 \n",
      "    62     4.166398   4.232919   0.411458                 \n",
      "\n",
      "CPU times: user 1h 14min 38s, sys: 21min 23s, total: 1h 36min 2s\n",
      "Wall time: 52min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.232919116814931, 0.41145834419876337]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 5\n",
    "learner.fit(1e-3, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 121 ms, sys: 687 ms, total: 808 ms\n",
      "Wall time: 6.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r01_05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe3a91d8efd4d82a764669d0eb30da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      4.168803   4.227467   0.409896  \n",
      "    1      4.170731   4.231776   0.416667                 \n",
      "    2      4.169062   4.233035   0.419271                 \n",
      "    3      4.170156   4.23254    0.418229                 \n",
      "    4      4.167404   4.226357   0.411979                 \n",
      "    5      4.169828   4.227555   0.4125                   \n",
      "    6      4.169787   4.227585   0.415104                 \n",
      "    7      4.16731    4.224222   0.414583                 \n",
      "    8      4.17211    4.240787   0.411979                 \n",
      "    9      4.170427   4.235757   0.414583                 \n",
      "    10     4.168479   4.230611   0.415625                 \n",
      "    11     4.167577   4.226602   0.417708                 \n",
      "    12     4.166107   4.223268   0.414063                 \n",
      "    13     4.169002   4.223104   0.415625                 \n",
      "    14     4.167931   4.223322   0.415625                 \n",
      "    15     4.170549   4.232208   0.4125                   \n",
      "    16     4.16786    4.224949   0.41875                  \n",
      "    17     4.166136   4.214938   0.411979                 \n",
      "    18     4.169681   4.224497   0.409375                 \n",
      "    19     4.169025   4.226922   0.409896                 \n",
      "    20     4.169314   4.229077   0.417708                 \n",
      "    21     4.167933   4.223091   0.416667                 \n",
      "    22     4.170352   4.227983   0.417188                 \n",
      "    23     4.167369   4.223209   0.415104                 \n",
      "    24     4.166043   4.220468   0.417188                 \n",
      "    25     4.166946   4.218988   0.417708                 \n",
      "    26     4.165158   4.21797    0.417708                 \n",
      "    27     4.16781    4.217671   0.41875                  \n",
      "    28     4.16708    4.21732    0.41875                  \n",
      "    29     4.167254   4.216978   0.418229                 \n",
      "    30     4.16753    4.216983   0.41875                  \n",
      "    31     4.16827    4.224921   0.410938                 \n",
      "    32     4.168174   4.222223   0.414583                 \n",
      "    33     4.168866   4.225046   0.416667                 \n",
      "    34     4.169077   4.226764   0.421875                 \n",
      "    35     4.17111    4.231488   0.420313                 \n",
      "    36     4.170392   4.23148    0.418229                 \n",
      "    37     4.169521   4.231111   0.417708                 \n",
      "    38     4.170252   4.226579   0.422917                 \n",
      "    39     4.167182   4.220117   0.409375                 \n",
      "    40     4.169184   4.219504   0.409896                 \n",
      "    41     4.166771   4.216795   0.413542                 \n",
      "    42     4.170616   4.221865   0.411458                 \n",
      "    43     4.167685   4.220197   0.409375                 \n",
      "    44     4.167924   4.218511   0.416667                 \n",
      "    45     4.167321   4.215502   0.408333                 \n",
      "    46     4.167219   4.2151     0.408854                 \n",
      "    47     4.166886   4.212042   0.409375                 \n",
      "    48     4.169595   4.215663   0.414583                 \n",
      "    49     4.169119   4.219333   0.411979                 \n",
      "    50     4.168115   4.218661   0.414063                 \n",
      "    51     4.16581    4.21564    0.410417                 \n",
      "    52     4.16603    4.213359   0.415625                 \n",
      "    53     4.167918   4.213909   0.414063                 \n",
      "    54     4.165592   4.213137   0.415625                 \n",
      "    55     4.166255   4.212457   0.413542                 \n",
      "    56     4.167239   4.211609   0.413021                 \n",
      "    57     4.167795   4.21161    0.411458                 \n",
      "    58     4.167718   4.212059   0.411458                 \n",
      "    59     4.169394   4.212336   0.411458                 \n",
      "    60     4.16613    4.212197   0.411979                 \n",
      "    61     4.165584   4.212216   0.411979                 \n",
      "    62     4.166057   4.21221    0.411979                 \n",
      "\n",
      "CPU times: user 1h 13min 18s, sys: 21min 38s, total: 1h 34min 57s\n",
      "Wall time: 52min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.2122102578481035, 0.41197917455186445]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Re-train 6\n",
    "learner.fit(1e-4, n_cycle=6, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 140 ms, sys: 666 ms, total: 807 ms\n",
      "Wall time: 6.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save model\n",
    "learner.save(chosen_model+'_r01_06')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get of classes and their indices\n",
    "with open(path/'names.txt', \"r\") as file:\n",
    "    classes = [line.rstrip().lower() for line in file]\n",
    "indices = [classes.index(c) for c in classes]\n",
    "with open(path/'names40.txt', \"r\") as file:\n",
    "    classes40 = [line.rstrip().lower() for line in file]\n",
    "indices40 = [classes.index(c) for c in classes40]\n",
    "indices_rm = list(set(indices)-set(indices40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def vggface():\n",
    "    m = torchvision.models.vgg16()\n",
    "    m.classifier._modules['6'] = torch.nn.Linear(4096, 2622)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_learner(path, trn_ds_name, val_ds_name, test_ds_name, classes, is_rgb, do_norm):\n",
    "    sz=224\n",
    "    wd=5e-4\n",
    "    bs=64\n",
    "    aug_tfms = [RandomRotate(20), RandomLighting(0.8, 0.8)]\n",
    "    stats_bgr_with_norm    = A([93.5940/255, 104.7624/255, 129.1863/255], [1.0, 1.0, 1.0])\n",
    "    stats_rgb_with_norm    = A([129.1863/255, 104.7624/255, 93.5940/255], [1.0, 1.0, 1.0])\n",
    "    stats_bgr_without_norm = A([93.5940, 104.7624, 129.1863], [1.0, 1.0, 1.0])\n",
    "    tfms = tfms_from_stats(stats_bgr_without_norm, sz, aug_tfms=aug_tfms, max_zoom=1.2) \n",
    "    data = ImageClassifierData.from_paths(path, tfms=tfms, bs=bs, trn_name=trn_ds_name, \n",
    "                                          val_name=val_ds_name, test_name=test_ds_name,\n",
    "                                          classes=classes, is_rgb=is_rgb, do_norm=do_norm)\n",
    "    learner = Learner.from_model_data(vggface(), data, metrics=[accuracy], crit=nn.CrossEntropyLoss())\n",
    "    return learner, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_metric_old(learner, data, cut=-13, is_acc=True, target='a.j._buckley', prune=False):\n",
    "    class_indexes = {c: i for i, c in enumerate(data.classes)}\n",
    "    filenames = [filepath[filepath.find('/') + 1:] for filepath in data.test_ds.fnames]\n",
    "    y_true = np.array([class_indexes[f[:cut]] if is_acc else class_indexes[target] for f in filenames])    \n",
    "    logits = learner.predict(is_test=True)\n",
    "    y_prob = to_np(F.softmax(VV(logits)))\n",
    "    if prune:\n",
    "        y_prob[::,indices_rm] = 0\n",
    "    return accuracy_np(y_prob, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_metric(learner, data, cut=-13, is_acc=True, target='a.j._buckley',  prune=False):\n",
    "    class_indexes = {c: i for i, c in enumerate(data.classes)}\n",
    "    filenames = [filepath[filepath.find('/') + 1:] for filepath in data.test_ds.fnames]\n",
    "    y_true = np.array([class_indexes[f[:cut]] for f in filenames])\n",
    "    logits = learner.predict(is_test=True)\n",
    "    y_prob = to_np(F.softmax(VV(logits)))\n",
    "    if prune:\n",
    "        y_prob[::,indices_rm] = 0\n",
    "    if not is_acc:\n",
    "        to_rm  = np.where(y_true == class_indexes[target])[0]\n",
    "        y_prob = np.delete(y_prob, to_rm, axis=0)\n",
    "        y_true = np.array([class_indexes[target] for i in range((len(filenames)-len(to_rm)))])\n",
    "    return accuracy_np(y_prob, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(path, model, test_benign, test_adv=None, trn_ds_name ='heal', val_ds_name ='valid', prune=False):\n",
    "    cut = -13 if test_benign[-3] != '_' else -16\n",
    "    metrics = [None, None, None]\n",
    "    trn_ds_name = trn_ds_name \n",
    "    val_ds_name = val_ds_name\n",
    "    test_ds_name = test_benign\n",
    "    is_rgb = False\n",
    "    do_norm = False\n",
    "    learner, data = get_learner(path, trn_ds_name, val_ds_name, test_ds_name, classes, is_rgb, do_norm)\n",
    "    learner.load(model)\n",
    "    metrics[0] = get_metric(learner, data, cut=cut,  prune=prune)\n",
    "    if test_adv == None: return metrics\n",
    "    test_ds_name = test_adv\n",
    "    learner, data = get_learner(path, trn_ds_name, val_ds_name, test_ds_name, classes, is_rgb=False, do_norm=False)\n",
    "    learner.load(model)\n",
    "    metrics[1] = get_metric(learner, data, cut=cut,  prune=prune)\n",
    "    metrics[2] = get_metric(learner, data, cut=cut, is_acc=False,  prune=prune)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Model M_00: [0.9427083333333334, 0.5690104166666666, 0.0]\n",
      "CPU times: user 16.1 s, sys: 6.05 s, total: 22.1 s\n",
      "Wall time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# All activations\n",
    "prune = False\n",
    "\n",
    "test_sets = ('test_crop_224', 'test2_crop_224')\n",
    "m_names = ['M_00']\n",
    "models  = ['mo_vf']\n",
    "\n",
    "rows = []\n",
    "for i, m in enumerate(models):\n",
    "    metrics = get_metrics(path, m, test_sets[0], test_sets[1], 'valid', 'valid', prune=prune)\n",
    "    row = list(metrics)\n",
    "    row.insert(0, m_names[i])\n",
    "    rows.append(row)\n",
    "    print(f' - Model {m_names[i]}: {metrics}')\n",
    "df=pd.DataFrame(rows, columns=['model','acc_benign', 'acc_trojan', 'asr'])\n",
    "path = Path('../data/vggface/')\n",
    "df.to_csv(path/fname[0], index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
